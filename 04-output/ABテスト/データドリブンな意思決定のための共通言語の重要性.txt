はい。 それでは。 チームでデータドリブンな意思決定ができる今日-- えー、 A/B テストナレッジシェアのところやってきます。 で、今日の目的としては、えーチームでデータドリブンな意思決定ができる 共通言語を、一人で A/B テストずっとやってると思うんですけど、まあそもそもなんか伝わってないなみたいな、なんで A/B テストするんだみたいなとこ全然伝わってないなって思ってたんで、共有させてもらいます。

で、なぜ今このナレッジシェアをやるのかについては、まあいろいろ A/B テストやってみて、まあなんかいいよねっていうところもあるんで、共有していきます。 で、スクラム開発の検査フェーズで、この試作って本当に効果あったの？ っていうのを定期的に振り返つつやると、まあ、次のフェーズにちゃんと生きていくんでめっちゃ大事だなって思ってるんで共有させてもらいます。 で、権威性だったり背景、背景のところ、なんでまあそもそも A/B テストをやろうかってところ、こんなことやってんのかみたいなところを共有させてもらうんですけど。 えー、まあなんか最初入った会社がソフトバンクで最年少で部長になった方が立ち上げたスタートアップに入ったんですけど、まあ iPhone 復旧の立役者の人ですね。 その当時 iPhone とかをめちゃくちゃ流行らすために奮闘していた人なんですけど、まあ本当にその人が行動量すごかったし。 えー、土日も普通に稼働してるし、ショートスリーパーで夜三時まで仕事して六時まで、六時に起きるっていうのが普通で、ほぼ寝ない時はもう三十分しか寝ないみたいな、ふざけた人だったんですけど、それでもその行動量でもなんかちゃんとグロースしなかった。 開発陣も結構優秀な方多くて、やってたんですけど、それでもグロースしなかったみたいなところがあるのと、あとは、まあそれをもって、DMM のプログラミングスクールの立ち上げだったり、大手企業のアプリの開発とかやらしてもらって、自分なりにいろいろ噛み砕きに行ったんですけど、それでもそういう大手のトヨタの開発だったり、バンダイの開発のところやらしてもらったんですけど、それでも星二とかだったんですよね。

で、まあそこで前職の方へも入って、いろんな会社さんを支援させてもらったりする中で、まあ知見、どうやってアプリ伸ばすんだろうみたいなところを伸ばせていけただからいいなっていうので入らせてもらったんですけど、その時にたまたまハイパーカジュアルゲームっていう業界に入らしてもらいました。 ハイパーカジュアルゲームっていうのがどういうものかっていうのは、なんか触ったら分かるんですけど、ほんとチャリ走みたいな軽いゲームになってきます。 で、このゲームがなんでこんなに広告とかとして流れてくるかって言ったら、ちゃんとデータドリブンにやってる業界なんで。 えー、なんだろう。 こんだけやってくるっていう感じです。 で、前職で得た知見みたいなところは、 KUGGLE で一ヶ月で金賞クラスのやつ取ったりするコンペで金賞とか取るような頭狂ったやつと一緒に共同しながらやったりしたんですけど、そういった PM みたいな PDM というか事業責任者みたいな立場のやつですね。 そいつと二人で、二人とプラスエンジニアのやつとやってたんですけど、その中で自分たちなりにめちゃくちゃ失敗してきて、で、何だろう。 失敗してきて、これが成功、成功しなかったやつで、成功したやつで、その中で 10 億ダウンロード達成した Kayak を立ち上げた部長の人から会食だったり、回、回、四回ぐらい会食行かせてもらって、なんかいろいろ学びをつつ、その後ですね、その後はその引き継いだ部長さんを自分たちのところに引っ張ってきて、学びを得るっていうところをやらせてもらってました。

参考にしてたところは Kayak の平山さんっていう人がいるんですけど、セガで長年働いてて、Kayakに入って、そのデータドリブンのところの開発をやってた人からメソッドみたいなところを得て、ビジュアライズ化するみたいなところをやってました。 で、このメソッドの普遍性みたいなところなんですけど、 VUDU だったり SUPERSONIC っていう大手企業があるんですけど、ゲーム業界の BeReal っていうのを買収した企業ですね。 で、その人たちのなんか内部 SDK みたいなデータ分析するための内部 SDK みたいなのがあるんですけど、その人たちがデータサイエンティスト、博士課程とかを終わらしたゴリゴリのデータサイエンティストとかがいる中でも、基本的には同じようなことをやってるのをなんかスパイ的なことをやって調査したりしたんで、基本的にはやり方はほぼ同じで、その後深掘りが-多分めちゃくちゃ上手で。 えー、なんでこうなってるか、なんでこの結果になったかみたいなところの深掘りは、その専属のデータサイエンティストとかがやってるんですけど、そうじゃない場合は、まあ基本的にそういうリソースがない場合は、これだけで十分だなっていうのは最近思ってます。 で、今これゲームの話じゃないかってなると思うんすけど、まあ A/B テストがしっかりしている企業は、まあそもそも伸びてるっていう統計結果も出ているし、 A/B テストでひたすらいい方を採用してったら、もう伸びるしか余地がないんで、まあ絶対良くなるよねみたいなところはあるんで、採用した方がいいかなっていうのはずっと思ってます。

で、まあ、機能開発するだけじゃあ、基本、機能開発して全部良くなるんだったら、全部の会社がめっちゃ良くなってるはずなんすけど、そうではないっぽいっていうのがあるんで、まあ A/B テストをして、しっかりいいものだけ採用していくっていうのが、まあゲームに限らず、どのウェブサービスとかにも応用して使えるのかなっていう感じです。 で、大前提としては、マーケット選びの重要性は後でやります。 で、なぜ A/B テストが重要なのかというと、まあ感覚と勘で、まあスティーブジョブズとかは多分また別格なんですけど、勘ってどうやって生まれるかっていうと、自分の分野で生まれるっていうのはあります。 その自分の得意とする分野でしか再現性はないっていうのは、えー、あって、何だろう、その積み上げてきた結果、分からないところから急に勘でやっても無理と思うんですよね。 で、そこを再現性を持ってやるために、データを見て、どれが良かったか良くなかったっていうのを A と B の中でやっていく中で、その中で勘っていうのは身に付くものであって、急にやって身に付くものじゃないかなっていうのは思ってます。

まあジョブスぐらいなんか自分の感覚がやってたらあるかもしれないですけど、そんなことはあんまりないのかなって思ってます。 で、A/B テストのメリットとしては、まあさっきも言ってるんですけど、絶対に改善していける既存のパターンと新規パターンの A と B を比較して、いい方をずっとやっていくんで、絶対に伸びていくっていうところがあるのと、まあ勘所が養われるんで、自分の知見領域での試行錯誤だったり、経験値として働いてくれる。 ま、どこにフォーカスすべきかわかるようになるみたいなところがあります。 で、リソースが少なくても改善できるポイントが見えるんで、このリソースでやるんだったらどこだろうみたいな。 これ工数かかるけどあんまり効果ないよねみたいなところも分かってくるんで、じゃあリソースが少なくて改善できるところを徹底的にまずやろうみたいな。
その後に余裕あればそのリソースかかるけどみたいなところの意思決定がどんどんできるようになってきます。 で、最後に繰り返すとどんどん当てられるようになってくるんですけど、まあ一般的な A/B テストの勝率は半分以下ぐらいの勝率かなっていうのは思っていて。 まあでも 10 億ダウンロードの部長レベルになると、頭の中で A/B テストに結果に基づいたシミュレーションがずっと回ってる感じになっていて、マーケット選びに関しても回ってるし、各 A/B テストの結果についても回ってる。 もうずっと頭の中でシミュレーションがもうできてる状態になってる感じはします。

で、そのデータで磨かれた勘は最終的に精度の高い直感になるんで、本当にもうほぼその人の得意分野だったら八割方ヒットゲームを出せるみたいな感じになってるんですけど、今なんかパズルゲームのところ調整してるみたいなんで、パズルゲームのところはやっぱりまだあんまり知見がないんで当てれてないっていう感じになります。 で、まあ具体のところ、今 A/B テストメリットのところを説明したんですけど、まあそもそもどんな感じで A/B テストのデータの仕込み方とかやるの？ みたいなところをやってみ -- えー、共有します。 で、まずファヤベースでログを押し込んでビッグクエリーに流し込むみたいなところの、えー、構成をまず基盤としてはとっていて。A/B テストの振り分け方法としては、まあ方法一で段階公開をやっていて、まあ方法二としてはコード内で乱数を振り分けてやるっていう方法をとってます。 で、ちょいちょい資料共有しながらやるんですけど、方法二の方-- 段階一 -- 方法一の方は多分今やってるんである程度わかるかなって思っていて、新しいとばー、古いバージョンを五十パーセント五十パーセントで振り分けるっていう方法をとってます。 で、方法二としては、コード内で乱数を振り分けて、まあ例えますけど、前一から十の乱数を適当に関数があるんで、振り分けて、で、まあその中で一、ニのユーザーはエイ軍、サン、ヨンのユーザーはビー軍、ゴロクのユーザーはシー軍みたいな感じで振り分けた上で、それをファイアベースのログに振り分けたデータをユーザープロパティとしてやって回してるみたいな感じですね。 で、そのエービーシーとか振り分けるのめっちゃめんどくさいと思うんで、まあ一から十まで振り分けて、ま今ここに、え、なんて言うんですか。 動作確認やっぱり必要になってくるんで、まあ方法二を取る場合は、え、アプリ内にデバッグ画面を用意して、パラメーターにポチポチ変えてテストパターンを確認できるようにするっていうのが大事です。

で、複数パターンの検証を円滑に回すことができるんですけど、まあ方法一と方法二は併用してやった方が基本的には良くて、えー、段階公開で見た場合は、まあそれで見れるんですけど、なんって言うんですか、古いバージョンと新しいバージョンどっちが勝ってるの？ みたいな。 見れると思うんですけど、方法二だけを採用した場合、もしその方法二のコード内のどこかに間違えてバグが混入した場合、昔のバージョンより悪くなってるみたいなところが考えられるっていうのはあります。 なので極力その方法にでも、えー、バグが混入しないように段階公開でまずやる。 で、こっち側にもしかしたらバグが混入してるかもしれないっていうリスクはあるんですけど、じゃあバグが混入してたらこんな結果に、何だろう、下がってるってことはバグが混入してるかもしれないなっていうのが分かりやすくなるっていうのはあります。 で、この中でも既存パターンと新規パターンっていうのを振り分けると、まあバグが混入してるかどうかっていうのが明確に分かってきます。 わかるかな？ で、まあ、 A/B テストの具体的なやり方と、まあなんか t 検定みたいなところを説明しないといけないけど、まあよくわかってないんで、やります。 で、統計検定の基本概念としては、良い水準は、えー、五パーセント。 で、検出力は通常八十パーセント。 効果量を検出したい値の大きさで、テスト設計の流れは、まあ、えー、こういう機能がいいんじゃないか。 じゃあ、この機能開発も仮説だと思っていて、この機能がいいと思ってるけど、ユーザーは本当に受け入れてくれてるのか？ みたいなところって、まあ本当にやってみないとわかんないところあるんで、それも仮説。 で、まあサンプルサイズを計算すると、最低まあこのぐらいは三百前後あれば、えー、ある程度の検出ができてくるんで、その t 検定みたいなところの要件満たしてくるんで、やっていきます。 で、テスト期間を決めるのは、まあ大体サンプル量にもよるんですけど、短期に効く施策と長期に効いてくる施策みたいなところの墨書きは若干大事になってくるんですけど。 まあ基本的に短期のやつが多いんですけど、長期のやつで言ったら、例えば前回もあったんですけど、グロナビのところ追加してみてどうかみたいな。 実は短期は伸びたけど、長期だとめちゃくちゃユーザーのリテンションが下がってるからやめた方がいいよね、とか出てくるんで。 そういう長期と短期の施策はなんか肌感、なんかうまく言語化できないですけど、やった方がいいかなっていう感じです。

で、判断基準の決め方、ていうと P値は零点零零五統計的に有意。 で、まあ勝ったら採用みたいな感じになります。 で、単純な勝ち負けだけではないんですけど、まあ勝ちは採用する、負けは採用しない。 磨き続けか、その機能のまあもしバグが混入してるとか、まあそもそもここ磨き込めてないよね、もっとこうした方がいいよねみたいなのがあるんだったら磨き込み続けるか判断をします。 なんで、なんかここは投資家じゃないですけど、ここの分野に投資した方がリターンが大きいかどうかみたいなところを考えて判断する。 みたいな感じで、たまには時にはなんか損切りが大事みたいな感じになります。

で、中立はほぼ変わらない。 開発が円滑に進む方を採用すると、えー、良くなります。 で、コア機能と非コア機能の判断でいうと、まあさっきの、えー、やつになるんですけど、コア機能、もうこれ入れないとこのゲーム成立、このアプリ成立しないよね、みたいな。 これあった方が絶対いいよね、みたいな。 もうコア機能になるものに関しては、勝つまで磨き込む選択肢は一定ありかなって思っていて。 非コア機能、例えばこんな感じのやつとかは、まあズルズル防止、まあ早めの判断で、えー、やめてもいいかなみたいな感じはあります。 で、あの、これなんかエンジニアメンバーだったり、PM目線で言ってた気がするんですけど、まあ別に他のところも応用ができる感じです。 で、 A/B テストはどこでも流用できて、まあコード上だけの話じゃなくて、まぁ本厳密にA/B テストするんだったら、条件を揃えて、まあ同じテスト期間を設けて、同じ日にやって、同じ時間帯にテストするみたいな感じが、まあ条件を揃えるために重要になってくるんですけど。 例えばあんまり変数として影響がない範囲だったら、まあ機能の対時間とかがあんまり影響ないところだったら、昨日のツイートと今日のツイートどっちが伸びたんだっけ？ みたいなやつを簡易判断の目安としてまんまできて、簡易判断の目安として、まあ条件がある程度揃っている場合だと、十から二十パーセント以上の改善が見られたら、まあ一定の n 数があったら、えー判断しやすい。
まあなんかそこら辺あんまり厳密にやったことないんですけど、全然応用できるかなっていう感じです。 で、まあ統計的優位性はサンプルサイズとその効果量で決まってくるんで、まあこんな感じで決まってくるんで、他のところにも全然応用が効きます。 まあとりあえずガンガン回していったら、完璧を求めすぎず、ただ結果には結果の判断みたいなとこは忠実に守ってやっていくと、完璧を求めすぎず、大きな差があるかどうかをまず見ることができるんで、まあ迷ったら検定するのがいいかなっていう感じですね。

で、まあ今なんかゲームのところで割と共有させてもらったんですけど、えー公開されてる AB テストのなんか非言語分野、ゲームみたいな分野は、なんかいろんな変数だったり、まあ単純に真似しても無理みたいな、真似しづらいみたいなところとか、結構一定あるかなって思ってるんですけど、こういうウェブサービスだったり、ビジネス系のアプリについてはいいですかな。 まあ一定言語化されてる言語かな。 ゲームじゃない分野に関しては、まあ公開されてる AB テストの事例だったり、行動経済学の研究、行動や心理学と経済学を合わせた研究とかが結構活発に動いてるんで、まあ Netflix だったり Amazon だったり、いろんな大手テック企業の AB テストの事例が落ちてたり、まあ行動経済学の研究結果とかが落ちてあったりするんで、すでにデータ化されているものは積極的に取り入れやすい。 もう効果がある程度証明されているので、まあ取り--