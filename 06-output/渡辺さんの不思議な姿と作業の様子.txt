じゃあ、失敗から学んだデータドリブン開発っていうので共有させてもらうんすけど、基本ABテストの内容だったり、なんでそういう感じで進めてったかみたいなところを前職のナレッジ元に共有させてもらいます。 で、なんかわからないところとかあったら都度聞いてもらったら答えます。

じゃあ始めていきます。 今日話す内容としては、なんかABテストする前、どんな感じだったかっていうのと、あとはなんでデータドリブンに始めたかと、その中での気づきと実際のサイクルとまとめと、ついでにプラスアルファでなんかマーケット選びとかもこういうのできるよっていうので共有させてもらいます。 はじめになんですけど、まあこの話をするところで言うと、なんか前前職最初スタートアップで入ったところとかで全然伸びなかったんで、どうやって伸ばすんだろうみたいなところを考えて、結果、ABテストとかを回すことでアプリグロースできるみたいなところがわかったんで、今回のスクラムするにあたっての検査フェーズで効果あったかっていうのをちゃんと振り返れるようにABテストしたいけど、共通言語として今回共有した方がいいかなって思ったんで共有させてもらいます。 で、伸びなかった時でいうと、最初入ったスタートアップのところ、ソフトバンクの最年少部長でなんかiPhone広めた人になるんですけど、土日もガンガン稼働するし、ショートスリーパーでなんか三時間しか寝なくていいみたいな感じで、短い時は三十分とかでほんとずっと仕事してるみたいな人で、めちゃくちゃ行動量すごかったんですけど、全然グロースしなかったみたいなところがあって、そこでなんか副業とかもトヨタの開発だったり、バンダイの開発とかも入らせてもらったんですけど、なんかアトミックデザインとかでコンポーネント設計だったりデザインとかめちゃくちゃ綺麗に設計してて、すごいなみたいなところを持ってたんですけど。 アプリリリースしてみたら星二の評価で、もう全然グロースしてない。

これ一日前とかにもなるんですけど、頻繁にアップデートしてるにも関わらず全然伸びてないみたいなところがあったんで、じゃあどうやって伸ばすんだろうみたいなところで、前職の三に入らせてもらったんですけど、アプリ支援してるところに入ったらわかるだろうみたいなところで入ったんですけど、アプリ支援のところでナレッジを得たっていうよりは、その事業部の中にハイパーカジュアルゲームっていうデータドリブンに開発していくゲームのスタイルがあるんですけど、そこの事業部のチーム二人いたんですけど、エンジニア一人とディレクター一人で少数のチームがいたんですけど、そこで人手が足りないからデータ分析手伝ってくれないかっていうので-やらせてもらったんすけど、なんかそこでのナレッジを共有させてもらいます。 で、そもそもなんか説明する前に、ハイパーカジュアルゲームのどんなものかっていうところがわからないと説明入ってこないと思うんで、共有させてもらうんですけど。

まあ定義としては本当によく広告で流れてくるゲームみたいな感じで。 えー、ま、広告収益で、収益を得ている超カジュアルなゲームになってきます。

で、全世界で配信してて、まあ言語とか全然使ってないんでもうゲームですぐ遊べて、広告収益で賄ってるみたいな感じです。 で、前職でリリースして当たったのはこの三作で一番右のやつが一番伸びてるって感じです。 で、まあこんな感じで、ゲームの種類は、まあハードゲーマーに刺さるやつとかあると思うんですけど、本当に一番ライトなところをターゲットにしてて、ゲーム開発してるみたいな感じのゲームのジャンルになってます。 で、用語解説。 ここからちょっと用語を二つ押さえておかないと伝わらないところがあるんで、説明しておくんですけど、コストパー、CPI っていうのがコストパーインストール、ユーザー一人あたりは、えー、インストールしてくれるのに広告費が何円かかったかみたいな感じですね。 なので自分たちが作ってたゲームでいうと１インストール六十円以下のゲームを作らないと、そもそも事業として成立しなかったんで、そこのチェックとかにこの CPI っていう指標を使ってテストしたりしてて、で、ROASっていうのがリターンオンアドスペンドって略なんですけど、そのさっきの広告費、ユーザーあたりの広告費に対して、そのユーザーがどのぐらい売上を立ててくれたかみたいな指標になっていて、さっきの六十円、六十円に対して六十五円だったらもう売り上げが五円買ってるから百五パーとかになると思うんですけど、それが百パーセント超えてきたら黒字化になってくるんで、そこの指標、実際にちゃんと収益として上がってってるかみたいなのを押さえるのがこのROASっていう指標になってきます。 で、まあ計算式でいうとのちもこんな感じになってますね。 で、そのハイパーカジュアルゲームの開発の流れでいうと、えー、まあMVPをここで考えて作って、実際に広告をメタとかフェイスブックに流してみて、何円でインストールされるかみたいなところを見て、さっきの六十円っていうラインがあるんですけど、六十円以下だったら撤退する。 六十円、六十円以上か、六十円以上だったら撤退して六十円未満だったらそのままゲームを作り込んでいくみたいな感じになるんで、本当に一週間でそのゲームを作り込むかどうかみたいなところを判断していくみたいな感じの手法をとってます。 で、従来のゲーム開発だともうこのゲーム作るってなったら二、三年かけて作るみたいな感じの開発手法をとってたんですけど、そうではなくて、データドリブンにもうマーケット選びから改善のサイクルまで全部回していくみたいな感じになってます。

で、主に二つのフェーズがあって、さっきの CPI っていうところのテストですね。 六十円を切ってるかどうかっていうのをまずテストして。 それをクリアしたら次のロアステストに移る。 えっと、改善フェーズですね。 広告費より売上が立てれるかっていうところをテストしていくみたいな感じになって。 で、結果百パーセント以上になるようだったら、正式にグローバルに広告をガンガン踏んでリリースしていくみたいなサイクルをとってます。 で、今回でいうとこのロアステスト、この改善フェーズの話になるんで、このロアステストの中身がメインになってきます。 だいたいなんか百本やって一から五本通るようなのが、ロアステスト、CPI テストになっていて、その後まあ三本中二点五本ぐらいが通過して、やっとちゃんと正式にリリースできるみたいな感じになってます。

で、学びの源泉としては、カヤックさんっていうハイパーカジュアルゲーム作っているところがあるんですけど、なんかそこの部長さんとかに話を聞いたりだったり、その部長さんを実際に引き抜いたわけじゃないですけど、チームにジョインしてもらったりしたんで、なんかその日本一の四年連続で一位取ってるところのナレッジをベースにやっていった感じになります。 で、大体このお二方から学びを得てきたんですけど、この畑田さんっていう左側の方がカヤックのハイパーカジュアルゲーム立ち上げた部長の方なんですけど、なんか元々セガでゲーム作ってたみたいで、ハイパーカジュアルゲームを作って、そこのあと独立した感じになっていて。 で、自分がチームにジョインした後に何か三、四回ぐらい飲みに行かせてもらって、どうやってゲーム作るんだよとか色々教えてもらった感じになります。 で、右側の村上さんという方がその後続の部長になってくるんですけど、なんか十億ダウンロードを達成した時にカヤックやめて。 

話者 2 17:52 
カヤックやめたって聞いたんで、自分たちのチーム来ないかって言ったら、プランナーとしてゲームのプランナーとしてこれから専任で行きたいみたいなことを考えてたフェーズみたいだったんで、フォーエムにジョインしていただいて、約四ヶ月間一緒に仕事をしてきた感じになります。

で、なんか参考になりそうな記事でいうとこの辺、この畑田さんが書いている、書いてるハイカジってどんな感じでやるんだよみたいなところ共有してるんですけど、まあ割と。 まあ普通にアプリ開発やってたらゲームのところちょっとあるんですけど、こんな感じで進めるんだみたいなのがわかってきます。 で、一番最初に参考にしたところでいうと、平山さんっていうカヤックの方、またエンジニアの方がいるんですけど、その人がABテストについてかなり詳しく書いてたんで、この人の記事をベースにどんどんデータドリブンに最初はやっていった感じになります。 あとはなんか後で気づいたんですけど、メルカリのカシラさんっていうデータのデータ事業部の担当だった人がいるんですけど、なんかその人となんか肌感みたいなのが、この人たちと同じようなこと言ってて、普通にえーゲームアプリ以外でも全然使える内容なんだなっていうのが分かったんで、なんか参考になるんで、気が向いたら見てください。

で、実際のABテストの基盤でいうとこんな感じでやっていて、えー、ファイアーベースだったりGA4とかがベースになってくるんですけど、そこでログを仕込んだものをビッグクエリに連携して、ダッシュボードでビジュアルライズしていくみたいな感じで構成していて、基本この流れでやってるんですけど、ファイアーベースリモートコンフィグとかABテスティングみたいなのを使ったら、簡易的にできたりするんで、この構成じゃなくてもあんまり工数かけたくないっていうんだったら、そういうのも全然使えます。 で、まあ基本ログにパラメーター割り振って、A軍とB軍で割り振ったりするのと、今基本 Android の段階公開とかでやってるんですけど、英軍と美軍で分けてもたまにバグが入り込んでくるリスクがあるんで、なるべく前バージョンと比べてバグが入ってないかっていうのを検知するために段階公開とかを使ったりするようにしてます。

ユーザーの振り分け方法なんですけど、なんかそんなに難しいことは全然しなくて。 0 から 1 の乱数を振り分けて、 0.5 未満なら英軍、 0.5 以上なら美軍みたいな感じで割り振ってやります。

で、なんか A と G 軍って書いてあるんですけど、乱数だったらいくらでも作れるんで、 0.2 未満なら A 軍とか作って、 ABCD とかでユーザーのプロパティを割り振ったりしたら、何個もテスト回したりします。 そのプロパティをファイアーベースにユーザープロパティとして保存したら、全イベントにそのユーザーの情報が紐づくように自動に設定されてあるんで、それを元にクエリ叩いて集計していくみたいな感じになります。

で、統計的な判断の基準でいうと、そのピーチっていうのを参考にしてるんですけど、このなんか英軍と美軍の結果がたまたまなのか、たまたまじゃないのかをこのピーチっていうのを使って 0 から 1 で判断するんですけど、 0.05 未満だったら基本あんまり 20回に一回ぐらいの精度でたまたまじゃない？ みたいなのが分かるんで、そういうのを使って判定してる感じになるんですけど。 なんか何すかね、普通にパッと見てユーザ数が多かったら差が出てたらもうピーチ見ないでも大体これ勝ってるなみたいな分かってくるんで、そんなに頻繁に使わなかったりもしてました。

で、実装フローでいうと、アプリの内部だとこれがフロントのものになるんですけど、基本フロントで AB テストやることもあると思うんすけど、なんか API の例えばレコメンドの設定をいじったみたいなやつも v1、v2とかで出し分けれると思うんで、それをフロントで取って AB テスト出し分けるみたいなのも全然できます。 でも基本このフローになっていて、アプリ起動時に既存設定があれば既存設定でユーザーに出し分けるみたいなところをやっていて、ない場合は新規に割り振ってローカルストレージとかに保存して、その後に A 軍と B軍で広告を出したり出さなかったりとか、出し分けた上でそのログをビッグクエリとか GA4 に GA4とかファイアベースに連携していくみたいな感じになります。

実際のコードがこんな感じですね。 乱数によって振り分けて、これはテスト一、テスト二、テスト三つ目になるんですけど、一つ目は ADAM の広告を表示するかだったり、起動時広告を表示するかみたいなのをテスト三つ目でやってます。 で、こっちでローカルストレージで永続化して、あとはもうファイアベースにそれぞれイベントを発火した時に流し込むみたいな感じにしてます。 なので、一回ここセットユーザープロパティっていうのを呼び出してるんですけど、それを一回呼び出したら、全イベントにそのユーザープロパティがそれぞれ割り振られるんで、ログを見てクエリで叩いてそれぞれ出し分けて集計するみたいな感じになってます。

で、なんか AB テストを複数回してると、なんだろう、確認が結構めんどくさくなるんで、今はこれアングラーズの設定画面、アプリの設定画面のところにあるんですけど、テスト環境だけこの開発者向けのオプションを表示して、一番上に広告を表示するかどうかみたいなのだったり、各広告の。 えー、種類によって出し分けたりするようにして、で、毎回アプリ消して入れ直すみたいなので、やるのめんどくさいんで、ま、ローカルストレージをリセットして、また乱数で振り分けてもらうみたいなところをやると、動作確認しやすいんで、こんな感じで動作確認しやすいようにしてます。

で、この AB テストで得たきっ、五つの気づきなんですけど、まあ基本 A 軍と B 軍でテストする、したりするんで、まあ絶対いい方を採用するから、絶対にアプリ自体は計測を間ちない、間違えない限り絶対によくなる方向に回っていくんで、まあひたすらこの AB テストをちゃんと回してったら、絶対よくなるように、なります。

で、つ目に変数。 なんか、し、外部要因だとどうしようもないところが多いと思うんですけど、基本アプリの内部で条件を合わせてテストしてるんで、なんだろう自分たちが操作できる変数に集中できるんで、まあアプリの体験を良くしたら絶対良くなるじゃないですか。 でも、外部要因で広告の非共感とか言われても、その数値見てても自分たちでアクション取れないことが結構多いと思うんですよね。 ただ、この AB テストにおいては、もう絶対に自分たちでえ、操作できる変数に集中してどうしようかみたいなのを考えれるんで、ま、自分たちで動かせるところにフォーカスして事業を伸ばしていくみたいなことができます。

で、三つ目に勘の正体みたいなところがわかってくるんですけど、まあ勘ってなんか自分の中に溜まったデータをもとに、まあなんか記憶だったりをもとに、こうやったらいいんじゃないかっていうのをやっていくんで、実際にこうやって AB テストを回した結果、こっちが良かった悪かったみたいなのをずっとた、積み重ねていくと、その中にたまったナレッジをもとに判断するんで、かなり精度の高い直感になってくるんで、ま、ほんとどんどん開発がスムーズにいっていく感じになります。 

話者 2 26:29 
で、最初のなんか CPI テストのところ本中本とかが最小当たるかどうかだったんですけど、もう基本その後はどんどん回してたってった結果、ほんとに本に本ぐらいは当たるような感じになってきたんで、ま、かなり精度が上がってきます。 で、なんか十億ダウンロードの部長兼三億ぐらいのゲームプランナーの方、ジョインしていただいて一緒に仕事してたんですけど、まあ基本なんかその直感のところで、大体もう頭の中でシミュレーションできてるんで、このゲームは売れるかどうかだったり、この施策はイケるかどうかみたいなところをもう脳内でシミュレーションして、もうダメそうなやつは全部弾いて、いけそうなやつばか、ばっかりピックアップしてるんで、まあな、なんていうんですかね、もう AB テストする前にも自分の中で AB テストしてるみたいな感じになってて、かなり精度が高かったです。 で、五つ目は、あ、コア体験の優先が大事だなっていうのに改めて気づかされたんですけど、アプリ開発やってたらいろんな機能をどんどん作ろうみたいなのに結構なりがちだなって思ってるんですけど、それよりはコア体験のところを優先することで、どんどんなんか数値が良くなっていく感じになっていて、なんかゲーム開発やってた時になんかレベルアップ機能だったり武器だったり、周辺機能をよくしたら伸びるんだろうって思って結構やってたんですけど、まあ、そん、そこに手を入れてもあんまり伸びなくて、結局。 実際はコア機能でより良い体験ができるようにやっていくと、本当に伸びてたっていうのが改めて気づきがあります。

で、なんかよくある勘違いのところでいうと、まあ小さいテストしかできない。 なんか赤いボタンか白いボタンかみたいなやつとかよくあると思うんですけど、まあそういうのじゃなくて、なんか新しい機能とか、の大規模な変更こそバグとかが入る率が高かったりするんで、まあ検証すべきだなと思っていて、まあ今だとコンポーネントごとに出し分けたりするんで、そんなに難しくないと思ってやっててもいいかなって思います。

で、つ目が複数テストは同時に回せないと思われがちなんですけど、なんか一個の AB テストじゃなくて、もう機能が被らなかったら、コンフリクトしなかったら複数に十個でも二十個でも百個でも回せるんで、ま、なんかかなり検証がすぷ、スムーズに回せます。 で三つ目は、えー、まあ結局仮説と検証の繰り返しなんで、なんか過去にうまくいったやつだけを繰り返してても、それ以上はあんまり伸びていかないんで、まあ新しい仮説を持ってきて、また実際に実験してみるみたいなところは結構やっていかないと、なんだろう、チームとしてグロースしていかなくなるんで、ここら辺も大事だなって思います。

で、四つ目が、まあ全ての修正をテストすべきではなくて、シンプルなバグ修正だったら、もうすぐに即時反映して、まあ AB テストの検証とかの負荷とかを減らして、そのリリースしていくのも大事になってきます。 で、これがなんかコードの話をよく今してたんですけど、まあコード外でも全然使えて、まあなんか TWITTER だったりのポストとかでもある程度条件揃えることはできると思うんで、なんか水曜と木曜の時とかだったらある程度条件揃ってると思うんで、まあそこで実際に A と B のポストで比較してみて、こっちの方、こういうつぶやき方の方が伸びるんだったらいけるなみたいなところもある程度できるんで、まあ厳密な AB テストじゃなくても、そのユーザー数によるんですけど、十パーセント二十パーセントぐらい伸びがあったら、えー、まあ統計的にはある程度確度高い。

テストみたいなところはできるんで、なんか他のところでも全然転用できるかなっていう感じです。 で、今ゲームの話をしてたんですけど、まあ他のところも全然WEBでもアプリのビジネス系のアプリでも全然いけるかなと思っていて。

まあNETFLIXだったりAMAZONだったり、まあABテストかなり回してたりするんで、なんて言うんですかね、ゲームより逆にビジネス系の方が何て言うんですか、非言語じゃなくて言語分野になってくるんで、えー真似しやすい、取り入りやすかったりするんで、なんかそこら辺の事例を参考に自分たちのアプリに当てはまるかみたいな、自分たちのアプリでもちゃんと良くなるかみたいなところは検証しやすかったりします。 あとはなんか心理学と経済学取り入れた学問になるんですけど、行動経済学っていう、なんかこういう見せ方をしたら人はこういう行動に移るみたいな研究されてる分野とかあるんで、まあECサイトとかでよく用いられてるんですけど、なんかそういうのも積極的に取り入れたら、まあ仮説検証確度の高い仮説検証を試しやすい、まあ非言語分野じゃないんで取り入れやすかったりするんで、かなり応用がききます。

で、今後どう活かすかなんですけど、まあ基本なんかABテストを回しましょうって話なんですけど、まあ勝ち負け中立の場合にどうやっていくかみたいなのをチームで決めたり、まあユーザーがどういう変化を起こしたかみたいなところを、まあこのスプリントの検証フェーズでやっていく感じがいいかなって思ってます。 で、まあ前職で回してた開発サイクルでいうと、火曜日と金曜日にリリースして、それまでの間にデータを収集しつつ並行開発して、で、そのデータを元に次週の施策はどうするかみたいな。

もうヶ月先とかじゃなくて、その都度その都度ユーザーの行動をこういうのを好むんだみたいなのが、このゲームにおいてこの行動をこのゲームにおいてこういう機能を好むんだみたいなのがわかってくるんで、都度毎週やる施策を考えて、えー試していった感じになります。 で、実際のABテストこの事例でいうとなんか個ぐらい一気に回したりすることあるんですけど、相手に当たるときにスローモーションになるかどうかだったり、あ、これですね。 こんな感じでスローモーションになる方がいいのか悪いのかみたいなところだったり、この左上のところがステージ数じゃなくてこの敵キャラビートンっていうんですけど、倒した数とステージ数、どっちがいいかみたいなところを、えーいろいろテストしてやってく感じに、まあ同時検証していく感じで回してたんですね。 で、実際のダッシュボードちょっと見づらいんですけど、画質荒くて小っちゃくて見づらいんですけど、この上の方でサマリーを出していて、ここにABテストをから六とかのサマリーを出していて、広告見られた回数だったり、エンゲージメント時間だったり、ステージのクリア数みたいなところを右側に出していて、ここにパラメーターがあるんですけど、ABテストのとかを選択したら、各リダーステージの離脱率だったり、平均クリア時間だったり、タップ数とリトライ数みたいなところが出るようになっていて、で、これがABテストのA軍とB軍みたいな感じで出し分けてるんですけど、今ヒートマップ状にしていて、この赤いところで離脱が起きてるみたいなところをみんなで見て、じゃあここで何で起きてるんだっけ？ 

話者 2 34:31 
みたいなところを話し合って次回の施策に生かしてったりします。 で、実際どんな感じで判定してたかっていうと、こんな感じですね。 なんか GOOGLE スライドでなんか判定とか施策とか管理してたんですけど、ここでいうと、なんか、なんか二十でこの黄色いやつとかじゃなくて緑かなんか黄色の敵キャラじゃなくてオレンジのやつを出すみたいな施策とかをやってたらかなり下がったんで、これを採用しようみたいなところだったり、なんか一番よく聞いたのが、えーステージの順番を置き換えるみたいなところが工数少なくてかなり効いてくるんですけど、それを毎回回して、どのステージの並びが一番いいかみたいなのをひたすら試すみたいなことをやって、これは結局あんまり差がつかなかったんで、継続してやって、他のところもこっちが一番良さそうだねみたいなところを判定して採用していくみたいな感じになります。 で、まあ勝ってたら即採用なんですけど、継続の場合はえーなんかあんまり差がない時は継続したりしたり、えーまあそもそもなんかメイン機能なのにメイン機能にしたいのに差が出なかった時はブラシャップをしたりとかします。

でも、負けの時はもう撤退だったり、その機能をなくすみたいなことをシビアに判定してました。 で、まあ勝ってたら採用で数値が同等なら磨き込むか撤退ですね。 で、中立だったらUXが良さそうな方だったり、開発がしやすい方を採用するみたいな感じでやってました。 で、なんかカイジこのABテストを回した改善の推移でいうと、ABテストを週に多分六、七個ぐらい回してたんですけど、五周でまあ1 日目の翌日の継続率が 2倍ぐらいになってて、広告の視聴回数が広告の視聴タイミングは変えてないんですけど、ゲームの体験がどんどん良くなった。 で、 3.0から8.9の大体 3倍ぐらいまで伸びるような感じになってました。 で、聞いた施策等効かなかった施策みたいなところはこんな感じになってるんですけど、ステージ大量追加してなんかガラッとステージの印象を変えることで伸びたりとか、キャラクターを変えてみたら逆に悪化してみたりとか。 ヘッドショットっていうなんか効果音だったり、テキスト出したらこれも悪化しなかった、悪化したみたいな感じがあるんで、なんか良くなると思った施策も全然効かないことがあるんで、まあ A B テストって結構必須だなという感じです。

で、このサイクルでずっと回してるんで、なんかどうやってやっていくかみたいなところをつど整理して、なんで効いたか効かなかったみたいなところをチームで現行化して、今回の失敗だったりをナレッジで資産化してみんなに共有して、で、ダッシュボード見ながらどうする？ みたいなところをずっとチームで回してた。 で、かなり改善サイクル早かったからっていう感じです。 で、まとめとしては、えーまあ行動力だけじゃなくて、ちゃんと A B テストで回したら良くなるっていうのを実感したんで、まあ行動力じゃなくて、ちゃんと検証のフェーズでしっかり検証するのも大事だなっていう感じです。 でまぁ、ちゃんとデータを根拠に直感を磨いていって、難しい時計とかなくても普通に基本的な手法で十分対応可能なんで、検査フェーズでしっかり振り返りをしましょうっていうまとめになります。

ここからプラスアルファなんですけど、今ロアースのところ共有させてもらったんですけど、 CPI テストのところはどんなことやってるかっていうと、まああんまり変わんないですけど、 MVP を作成して広告配信をして円以下になるかどうかみたいなところをやって、円以下なら号で、それ以上だったら撤退するみたいなところをずっとやってて、やってて。 で、なんか他の業界でも全然使えそうだなって思っていて。 今 CPI テストのところをやってたんですけど、普通にテストマーキーやってるみたいな感じに近いんで、今あんまりハイパーカジュアルゲーム以外の知見あんまりないんですけど、ポイ活アプリだったり健康系のフィットネスだったらリテンションこのぐらいになるみたいなところある程度多分ディープリサーチとかしたら出てくると思うんで、実際に MVP 作ってみて行けそうかどうかみたいなラインを決めてやれば MVP MVP の段階でもう行けそう、行けなさそうみたいなところがある程度わかってくるんで、まぁちょっと調べないと撤退基準とか難しいと思うんですけど、結構マーケット選びの時にこの手法は使えるんじゃないかなっていう感じです。 ご清聴ありがとうございました。 なんか質問とか聞きたいところあれば受け付けます。 

話者 1 40:04 
おはようございます。三村さん。

話者 3 40:06 
はい。 えーと、まあ、なんかちょっと通話中のメッセージ、あの Google の MEET のチャットのところにも来たんですけど、なんかそのー、例えば大手テックの事例とかっていうのは、なんか具体的にそういう A B テストの事例とかがまとまってる文献とかってあったりするんですか？ 

話者 2 40:24 
そうですね。結構あるんですけど、なんかデュオリンゴとかも結構出してるイメージ。オープンに出してるイメージで、NETFLIXも確か結構出してて。

話者 3 40:35 
独自のなんかドメインで会社が出してるみたいな感じなんですか？

話者 2 40:42 
そうですね。 なんか最近見つけたのでいうとなんか NETFLIX のテックブログとかでもちょいちょい出してて、あの NETFLIX のサムネなんか各ドラマのサムネって変わるようになってるんですよね。 変わるようにしたらそのクリック率がめちゃくちゃ上がるみたいな。

なんかよく見てたら気づくと思うんですけど、アニメのサムネが毎回変わってるんですよね。 

話者 3 41:10 
うん、うんうんうん。

話者 2 41:11 
そこで上がったみたいなやつがここら辺にたまに上がってきたりするんで。 あとなんか酒井さんが言ってたんですけど、デュオリンゴだとアプリのアイコンを変えることで、なんかアプリの起動回数がめちゃくちゃ増えたみたいなやつもあるので、なんかそういうのがかなり参考になるですね。

AMAZON も確かやってますね。 そういうの。 

話者 3 41:36 
うん、うん、うんうん。ありがとうございます。これか。

話者 2 41:45 
あと、あと他にあったりしますか？大丈夫そう。渡邊さんどうぞ。

話者 1 41:58 
えーっと、セグメントの切り方なんですけど。 あれってもう乱数で、まあ、あの 1 から 10 とか、なんかそれぐらいの単位でよくって、まあだから 0 から 5 までを Aグループ、 6 から 10 までを Bグループみたいにするみたいな感じですかね。 

話者 2 42:19 
そうですね。そうですね。その感じです。

話者 1 42:22 
そのなんかアングラでいうところで、もうなんかその乱数でいいのかとかっていうのが、その、あの結構特性があって、オフショアとオフショアって言って、その。 えーと、海の沖とかでこう、する人たちに対してセグメントを切った方がいいケースもあるし、で、陸っぱり、陸のする、岡でこう釣りをする人たちに対して、あと漁師とかもありますよね。

シーバスとかボートシーバスとか、流さんでしたり、イカとか、何かそういう単位でもなく、もう本当にランダムでいいのか。 これはもうゲームのゲーム業界の特性なのかでいうと、どういうような切り分け方がこう業界によってなんかあるんですかね、ケースとしても。 

話者 2 43:14 
そうですね。なんかこの日、平山さんっていう方の記事でも、なんか一応そのセグメント切った方がいいんじゃないかみたいな。

話者 1 43:23 
はいはいはい。

話者 2 43:23 
セグメント切った中でABテスト回した方がいいんじゃないかみたいなのもあるんですけど。

話者 1 43:30 
はい。

話者 2 43:32 
全世界対象にしてるんで、百何十、百九十何か国とかあったらユーザーの傾向が全然違ってて。

話者 1 43:39 
うん。

話者 2 43:41 
そこに分析の負荷、開発の工数とかやっぱかかってくるんで、そこをやるよりは、もうひたすらABテストで乱数振り分けるみたいなことをやってるんですけど。２年前まではそんな感じでやってたんですけど、今だと多分ちゃんとセグメントを切って、ハードユーザー、コアユーザー、ライトユーザーみたいな感じで出し分けることも全然工数としてはいける感じになってるんで。

なんか渡辺さんの言うように、そんな感じでセグメント切った上で乱数で振り分けるみたいなのもありかなって思うんすけど、ちょっとやっぱ工数かかるんで。 

話者 1 44:17 
工数、うん。

話者 2 44:18 
余裕ある時にチャレンジしたいなっていう感じですかね。

話者 1 44:23 
だから、この前やってたそのタブ切り替え、あとヘッダーが白くなるやつとかでしたっけ？

話者 2 44:28 
そうです、そうです。

話者 1 44:28 
タブが五つになって、あの、あの辺は、あれはごめんなさい、えっと、ABテストというやり方の仕方としてはもう段階公開を五十パーセントにしたみたいな、そういう感じでしたっけ？

話者 2 44:43 
そうですね。あのお時は段階公開で五十パーでやってる感じですね。

話者 1 44:49 
あぁー。

話者 2 44:49 
今IOSでやってる広告のやつは、アプリ内部で乱数で振り分けてやってますね。

話者 1 44:57 
あ、そうなんですね、なるほど。 だから、ぐろなびとかはもうこの新しいバージョンを公開率五十パーセントにした方がその対象者になるし、それに引っかからなかった人は、前の旧ユーザーとして引き続き使うことで、まあこうABテストを仕掛けている。

で、今回のAPPLOVINっていうやつでしたっけ？ あれはどんな感じでやってるかというと、乱数用意して、えー、個々のコンポーネントにも広告表示させるかどうかみたいなですか？ 

話者 2 45:37 
そうですね、そうです。 何て言うんですかね。

基本やってること変わんないんですけど、えー、ぐろなびの方ってテストが一個じゃないですか。 テストが一個だったら、もう段階公開でGoogleが勝手に乱数じゃんつけて振り分けてくれるので。 

話者 1 45:52 
そうですね。

話者 2 45:52 
五十パー五十パーでいいんですけど、今回の広告でいうと、三つのテストを同時に走らせる感じになってたんですよね。

話者 1 45:59 
おお三つ。

話者 2 46:00 
だったら段階公開で三つのテストでどれが影響がでかいかみたいなやつって、検証、ふた、二群に分けるだけじゃ検証できないじゃないですか。

話者 1 46:11 
できないですね。

話者 2 46:12 
なんで、その各独立したセグメントにするために、この一番上では、A群は広告をまず出すか出さないか。 で、もう一個のやつでは起動時広告を出すか出さないかみたいなのを、本当にユーザーそれぞれにやると、どれが影響がでかいとか、どれが良かったか悪かったみたいなのが独立したテストなんでわかるっていう感じですね。 

話者 1 46:38 
うんうん、うんうん。 そこでセブンデイズのリテンション、ワンデイズのリテンションとかも見てて、起動広告でも全然リテンション変わんないんじゃないかっていうことになったら、まあちょっと広めにやってみようとか、そういうことですよね。 

話者 2 46:54 
そうですね。そうですね。そういう感じです。

話者 1 46:55 
うん。 なるほど、了解。

それはだから、さっきの、えっとまあ、アプリを起動時に乱数で割り振ってローカルストレージに置いといて、ADHOCがイネーブルの人なのか、アプリ起動の広告がイネーブルの人なのかとかって分けて、アプリ内で切り分けるってことですか？ 

話者 2 47:21 
そうですね。アプリ内で切り分けてる感じですね。

話者 1 47:24 
あ、はいはいはいはい。で、でも、あのセットプロパティでしたっけ？ユーザープロパティとかでファイアベースでイベントを送ってるので、どのユーザーがっていうのは追えるってことですね。

話者 2 47:37 
そうですね。全イベントにそのユーザープロパティが紐付いてくるんで、全部のイベントに対してそのクエリを叩けば出てくるって感じです。

話者 1 47:48 
了解です。確かにユーザープロパティって今ユーザー ID しかセットしてなかったと思うので、多分それにいろんないろんなパラメーターを追加してみたって感じですか。

話者 2 47:57 
そうですね。イメージそんな感じですね。

話者 1 48:00 
わかりました。はい。ありがとうございます。ちょっと具体的な話になっちゃいました。

話者 2 48:06 
ありがとうございます。あとは大丈夫そうですか？大丈夫そうなんで、渡辺さんにお戻しします。

話者 1 48:17 
あ、はい。ありがとうございます。OK です。はい。じゃあ、えーと、ちょっと長くなっちゃったんですけど。他は何か共有しておきたいこととか、漏れていたところってあったりしますか？

話者 3 48:44 
大丈夫です。

話者 1 48:45 
でですかね。 はい、分かりました。 えーと、そしたら、ここにはないかな、来週が。 はい。

まあ来週、ちょっとあれですね。 あの、いろんな方が、あの、退職されるので、それのお別れっていうところの 日。 安野さん、中西さんはちょっと無理なんですね。 北海道からだと思います。 

話者 4 49:17 
あーですね。あれですか？

話者 1 49:19 
了解です。

話者 4 49:20 
オンラインでってことですか？

話者 1 49:22 
あ、いや、あのー、まあまあでも都合が合えばっていうところだったと思うので。

話者 4 49:30 
あー。

話者 1 49:31 
あ、てかあれですよね。年内とかどうかな？来られます？

話者 4 49:35 
いやー、行かないんですよね。

話者 1 49:36 
あー、まあまた来年って感じですかね。

話者 4 49:39 
そうですね。

話者 1 49:41 
あ、了解です。

話者 4 49:42 
なんかちょっと、猫が私がいなくなったらすぐ鳴くんで。ちょっと行けないですね。単純に。

話者 1 49:54 
切ないですもんね、あの鳴き声。

話者 4 49:58 
そうですね、前までそんなことなかったんですけどね。引っ越ししてからすごい鳴くようにって言ってました。

話者 1 50:08 
あー。あ、 

話者 3 50:08 
なんか 二匹目とかの。あ、はい、あ、いや大丈夫です、大丈夫です。

話者 1 50:15 
中西さん、飼わないですか？

話者 4 50:17 
まあ二匹目ですから。っていうのは、一匹しか飼えないんですよね。

話者 1 50:21 
あ、期限あるんですか？

話者 4 50:24 
ありますもんね。

話者 1 50:27 
あー。安野さんとかも気にするとバンバン三匹目とかいいんじゃないですか？

話者 2 50:34 
でもあれですね。なんか二匹目の敷金みたいなやつを払ったら二匹目全然 OK だったですね。交渉したら。

話者 1 50:44 
交渉次第。

話者 2 50:44 
交渉次第ですね。まあ一匹も二匹も大して変わんないんで、許してくれるんじゃないですかね。

話者 1 50:52 
まあまあまあ。木村さん何かさっき言いかけてませんでしたか？

話者 3 50:57 
あの 12月の 26日。12月の 25 日が最終出社だと思うんですけど、最終出社っていうか、また会社的に、会社的にも最終出社だと思うんですけど、デベロッパーミーティングって金曜日じゃないですか。

話者 1 51:08 
あー、はい。

話者 3 51:10 
最後のデベロッパーミーティングの最後ってあ、もう来週になります？そうなると。

話者 1 51:15 
えーっと、いや、今から書いておきます。 ちょっとこれは最後させてください。

えーっと、そのまま左に。 中西さんとかも大丈夫そう、中西さん。 安野さん。 そこアニオニキウデもあれだったので OK ですね。 ちょっと来週だけ話をね。 

話者 3 51:44 
再来週ですかね。

話者 1 51:46 
来週です。

話者 3 51:47 
はい。

話者 1 51:49 
この予定だけ。

話者 3 51:54 
まあだからそれが最後のデヴズミーティングっていう。

話者 1 51:58 
はい。

話者 3 51:59 
年内は。

話者 1 52:01 
はい。

話者 3 52:02 
OK です。分かりました。

話者 1 52:07 
いいです。そしたら以上ですかね。

話者 3 52:13 
はい、大丈夫です。

話者 1 52:15 
はい。では、えーと、引き続きどうぞよろしくお願いします。

話者 3 52:19 
よろしくお願いします。安野さん、ありがとうございました。

話者 2 52:21 
ありがとうございました。よかったよな。いろいろやってんな。ABテストの結果、そんなに？ここら辺に、まとまってたりしますね。
